"""
Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - ç„¡æ–™ç‰ˆ
Ollama + HuggingFace Embeddingsã‚’ä½¿ç”¨
"""
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
import os
from dotenv import load_dotenv
import logging

from src.vector_store_free import VectorStoreManager
from src.chatbot_free import JTBCSupportChatbot
from src.scheduler import UpdateScheduler

# ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
app = Flask(__name__)
CORS(app)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
chatbot = None
scheduler = None

def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"""
    global chatbot, scheduler
    
    use_local = os.getenv('USE_LOCAL_LLM', 'true').lower() == 'true'
    
    if use_local:
        logger.info("ğŸ†“ ç„¡æ–™ç‰ˆãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ï¼ˆOllama + HuggingFaceï¼‰")
    else:
        logger.info("ğŸ’° OpenAIç‰ˆãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.error("OPENAI_API_KEY not found in environment variables")
            return False
    
    try:
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–
        logger.info("Initializing vector store...")
        api_key = os.getenv('OPENAI_API_KEY') if not use_local else None
        vs_manager = VectorStoreManager(use_free=use_local, openai_api_key=api_key)
        vectorstore = vs_manager.load_or_create_vectorstore()
        
        # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®åˆæœŸåŒ–
        logger.info("Initializing chatbot...")
        model = os.getenv('LOCAL_LLM_MODEL', 'gemma2:2b') if use_local else None
        chatbot = JTBCSupportChatbot(
            vectorstore=vectorstore, 
            api_key=api_key,
            use_local=use_local,
            model=model
        )
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®é–‹å§‹
        update_interval = int(os.getenv('UPDATE_INTERVAL_HOURS', 24))
        logger.info(f"Starting scheduler (interval: {update_interval} hours)...")
        scheduler = UpdateScheduler(interval_hours=update_interval)
        # åˆå›æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ï¼‰
        # scheduler.start()
        
        logger.info("Application initialized successfully")
        return True
        
    except Exception as e:
        logger.error(f"Error initializing application: {e}")
        import traceback
        traceback.print_exc()
        return False


@app.route('/')
def index():
    """ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸"""
    return render_template('index.html')


@app.route('/api/chat', methods=['POST'])
def chat():
    """ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json()
        question = data.get('question', '')
        
        if not question:
            return jsonify({'error': 'No question provided'}), 400
        
        if chatbot is None:
            return jsonify({'error': 'Chatbot not initialized'}), 500
        
        # å›ç­”ã‚’ç”Ÿæˆ
        response = chatbot.ask(question)
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Error in chat endpoint: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/suggestions', methods=['GET'])
def suggestions():
    """ã‚µã‚¸ã‚§ã‚¹ãƒˆè³ªå•ã‚’å–å¾—"""
    try:
        if chatbot is None:
            return jsonify({'error': 'Chatbot not initialized'}), 500
        
        suggested = chatbot.get_suggested_questions()
        return jsonify({'suggestions': suggested})
        
    except Exception as e:
        logger.error(f"Error in suggestions endpoint: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/status', methods=['GET'])
def status():
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    use_local = os.getenv('USE_LOCAL_LLM', 'true').lower() == 'true'
    return jsonify({
        'status': 'running',
        'chatbot_ready': chatbot is not None,
        'scheduler_running': scheduler is not None,
        'mode': 'free' if use_local else 'openai',
        'model': os.getenv('LOCAL_LLM_MODEL', 'gemma2:2b') if use_local else 'gpt-4o-mini'
    })


@app.route('/api/update', methods=['POST'])
def trigger_update():
    """æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    try:
        if scheduler is None:
            return jsonify({'error': 'Scheduler not initialized'}), 500
        
        # æ›´æ–°ã‚’å®Ÿè¡Œ
        scheduler.update_data()
        
        return jsonify({'message': 'Update triggered successfully'})
        
    except Exception as e:
        logger.error(f"Error triggering update: {e}")
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    if initialize_app():
        # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        port = int(os.getenv('FLASK_PORT', 5000))
        print()
        print("=" * 60)
        print("ğŸš€ JTBCã‚µãƒãƒ¼ãƒˆãƒ‡ã‚¹ã‚¯ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ - ç„¡æ–™ç‰ˆ")
        print("=" * 60)
        print(f"ğŸŒ URL: http://localhost:{port}")
        print("ğŸ’° ã‚³ã‚¹ãƒˆ: å®Œå…¨ç„¡æ–™ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰")
        print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«:", os.getenv('LOCAL_LLM_MODEL', 'gemma2:2b'))
        print()
        
        app.run(
            host='0.0.0.0',
            port=port,
            debug=os.getenv('FLASK_ENV') == 'development'
        )
    else:
        logger.error("Failed to initialize application")
